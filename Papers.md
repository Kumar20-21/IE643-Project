# Time Series Papers and Resources

## Foundational Transformer Papers

1. **Attention Is All You Need**  
   [https://arxiv.org/pdf/1706.03762](https://arxiv.org/pdf/1706.03762)  
   *Transformer Paper*

---

## Benchmarking & Dataset Papers

1. **TAB: Unified Benchmarking of Time Series Anomaly Detection Methods**  
   [https://arxiv.org/abs/2506.18046](https://arxiv.org/abs/2506.18046)

2. **CATCH: Channel-Aware multivariate Time Series Anomaly Detection via Frequency Patching**  
   [https://arxiv.org/abs/2410.12261](https://arxiv.org/abs/2410.12261)  
   *Dataset paper and well cited for good references*

---

## Vision Transformers & Time Series

1. **Mantis: Lightweight Calibrated Foundation Model for User-Friendly Time Series Classification**  
   [https://arxiv.org/abs/2502.15637](https://arxiv.org/abs/2502.15637)  
   *First ViT paper for time series*

2. **Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers**  
   [https://arxiv.org/abs/2506.08641](https://arxiv.org/abs/2506.08641)  
   *Paper using ViT as a pre-trained model*

3. **Time Series as Images: Vision Transformer for Irregularly Sampled Time Series**  
   [https://openreview.net/forum?id=ZmeAoWQqe0](https://openreview.net/forum?id=ZmeAoWQqe0)

4. **An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale**  
   [https://arxiv.org/abs/2010.11929](https://arxiv.org/abs/2010.11929)  
   *Vision Transformer paper*

---

## Transformers & Mamba in Time Series

1. **Mamba: Adaptive Anomaly Transformer with Association Discrepancy for Time Series**  
   [https://arxiv.org/abs/2502.07858](https://arxiv.org/abs/2502.07858)

2. **A novel Mamba-hypergraph enhanced time-frequency fusion network for multivariate time series classification**  
   [https://link.springer.com/article/10.1007/s40747-025-02016-2](https://link.springer.com/article/10.1007/s40747-025-02016-2)  
   *Seems to be the first article mixing time and frequency domain*

---

## Pretraining & Synthetic Data

1. **CauKer: Classification Time Series Foundation Models Can Be Pretrained on Synthetic Data Only**  
   [https://arxiv.org/abs/2508.02879](https://arxiv.org/abs/2508.02879)

---

## Surveys

1. **A Survey on Deep Learning based Time Series Analysis with Frequency Transformation**  
   [https://doi.org/10.1145/3711896.3736571](https://doi.org/10.1145/3711896.3736571)

2. **A Survey of Deep Anomaly Detection in Multivariate Time Series: Taxonomy, Applications, and Directions**  
   [https://doi.org/10.3390/s25010190](https://doi.org/10.3390/s25010190)

3. **Time Series Analysis in Frequency Domain: A Survey of Open Challenges, Opportunities and Benchmarks**  
   [https://arxiv.org/abs/2504.07099](https://arxiv.org/abs/2504.07099)

4. **Deep Anomaly Detection for Time Series: A Survey**  
   [https://doi.org/10.1016/j.cosrev.2025.100787](https://doi.org/10.1016/j.cosrev.2025.100787)

5. **Harnessing Vision Models for Time Series Analysis: A Survey**  
   [https://arxiv.org/abs/2502.08869](https://arxiv.org/abs/2502.08869)

---

## Repositories

1. **Time-Series Transformers Review Repository**  
   [https://github.com/qingsongedu/time-series-transformers-review](https://github.com/qingsongedu/time-series-transformers-review)  
   *A Good Repo*

---

## Reinforcement Learning in time series

1. **A Deep Reinforcement Learning Approach for Early Classification of Time Series**  
   [https://doi.org/10.23919/EUSIPCO.2018.8553544](https://doi.org/10.23919/EUSIPCO.2018.8553544)

